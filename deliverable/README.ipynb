{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow and Seldon\n",
    "\n",
    "End to end example integrating MLFlow and Seldon, with A/B testing of the models.\n",
    "The slides accompanying this demo can be [found here](https://docs.google.com/presentation/d/1QXiOZkd_XNw6PbUalhYDajljKYQjgKczzNncTyLk9uA/edit?usp=sharing)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "\n",
    "### Python Libraries\n",
    "\n",
    "The training part of the example assumes that you are able to run `mlflow` on your local environment. It is recommended to use this in a fresh conda environment.\n",
    "To set it up, you can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kubernetes\n",
    "\n",
    "The serving side of the example assumes that you've got access to a Kubernetes cluster where Seldon Core is installed.\n",
    "If you don't have access to a local cluster, feel free to use [`kind`](https://kind.sigs.k8s.io/).\n",
    "\n",
    "For instructions on how to install Seldon Core, please check their [setup docs](https://docs.seldon.io/projects/seldon-core/en/latest/workflow/install.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytics\n",
    "\n",
    "Additionally, after we deploy the models, we will compare their performance using Seldon Core's integration with Prometheus and Grafana.\n",
    "For that part to work, we will need to install Prometheus and Grafana.\n",
    "\n",
    "To speed things up, we can do this through the [`seldon-core-analytics` chart](https://docs.seldon.io/projects/seldon-core/en/latest/charts/seldon-core-analytics.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Training\n",
    "\n",
    "This first section will cover how to train models using MLFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLflow Project\n",
    "\n",
    "The MLproject file defines:\n",
    "- The environment where the training runs.\n",
    "- The hyperparameters that can be tweaked. In our case, these are $\\{\\alpha, l_{1}\\}$.\n",
    "- The interface to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./training/MLproject\n",
    "name: mlflow-talk\n",
    "\n",
    "conda_env: conda.yaml\n",
    "\n",
    "entry_points:\n",
    "  main:\n",
    "    parameters:\n",
    "      alpha: float\n",
    "      l1_ratio: {type: float, default: 0.1}\n",
    "    command: \"python train.py {alpha} {l1_ratio}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to have a single command to train the model. \n",
    "\n",
    "``` bash\n",
    "$ mlflow run ./training -P alpha=... -P l1_ratio=...\n",
    "```\n",
    "\n",
    "For our example, we will train two versions of the model, which we'll later compare using A/B testing.\n",
    "\n",
    "- $M_{1}$ with $\\alpha = 0.5$\n",
    "- $M_{2}$ with $\\alpha = 0.75$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/12/19 16:49:07 INFO mlflow.utils.conda: === Creating conda environment mlflow-62f9b69251cbd655a1308303dace7190a5738de8 ===\n",
      "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 22.11.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 22.11.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "scikit-learn-1.1.3   | 6.4 MB    | ##################################### | 100% \n",
      "certifi-2022.9.24    | 155 KB    | ##################################### | 100% \n",
      "pip-22.3.1           | 2.7 MB    | ##################################### | 100% \n",
      "setuptools-65.5.0    | 1.1 MB    | ##################################### | 100% \n",
      "libgfortran5-11.3.0  | 1.4 MB    | ##################################### | 100% \n",
      "mkl-service-2.4.0    | 45 KB     | ##################################### | 100% \n",
      "numpy-1.23.4         | 11 KB     | ##################################### | 100% \n",
      "mkl_random-1.2.2     | 273 KB    | ##################################### | 100% \n",
      "libffi-3.4.2         | 127 KB    | ##################################### | 100% \n",
      "joblib-1.1.1         | 383 KB    | ##################################### | 100% \n",
      "numpy-base-1.23.4    | 6.4 MB    | ##################################### | 100% \n",
      "python-3.8.15        | 12.7 MB   | ##################################### | 100% \n",
      "fftw-3.3.9           | 2.0 MB    | ##################################### | 100% \n",
      "libgfortran-5.0.0    | 142 KB    | ##################################### | 100% \n",
      "mkl_fft-1.3.1        | 165 KB    | ##################################### | 100% \n",
      "scipy-1.9.3          | 20.3 MB   | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: - \n",
      "\n",
      "    Installed package of scikit-learn can be accelerated using scikit-learn-intelex.\n",
      "    More details are available here: https://intel.github.io/scikit-learn-intelex\n",
      "\n",
      "    For example:\n",
      "\n",
      "        $ conda install scikit-learn-intelex\n",
      "        $ python -m sklearnex my_application.py\n",
      "\n",
      "    \n",
      "\n",
      "done\n",
      "Installing pip dependencies: \\ Ran pip subprocess with arguments:\n",
      "['/Users/josh/opt/anaconda3/envs/mlflow-62f9b69251cbd655a1308303dace7190a5738de8/bin/python', '-m', 'pip', 'install', '-U', '-r', '/Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/training/condaenv.x0w9p4s8.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting mlflow\n",
      "  Downloading mlflow-2.0.1-py3-none-any.whl (16.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.5/16.5 MB 21.1 MB/s eta 0:00:00\n",
      "Collecting gunicorn<21\n",
      "  Using cached gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "Collecting click<9,>=7.0\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Collecting entrypoints<1\n",
      "  Using cached entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Collecting importlib-metadata!=4.7.0,<6,>=3.7.0\n",
      "  Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
      "Collecting cloudpickle<3\n",
      "  Using cached cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting pyyaml<7,>=5.1\n",
      "  Using cached PyYAML-6.0-cp38-cp38-macosx_10_9_x86_64.whl (192 kB)\n",
      "Collecting pandas<2\n",
      "  Downloading pandas-1.5.2-cp38-cp38-macosx_10_9_x86_64.whl (11.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.9/11.9 MB 24.7 MB/s eta 0:00:00\n",
      "Collecting matplotlib<4\n",
      "  Downloading matplotlib-3.6.2-cp38-cp38-macosx_10_12_x86_64.whl (7.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.3/7.3 MB 20.7 MB/s eta 0:00:00\n",
      "Collecting shap<1,>=0.40\n",
      "  Downloading shap-0.41.0-cp38-cp38-macosx_10_9_x86_64.whl (436 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 436.5/436.5 kB 7.3 MB/s eta 0:00:00\n",
      "Collecting Jinja2<4,>=2.11\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting docker<7,>=4.0.0\n",
      "  Downloading docker-6.0.1-py3-none-any.whl (147 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 147.5/147.5 kB 3.9 MB/s eta 0:00:00\n",
      "Collecting sqlalchemy<2,>=1.4.0\n",
      "  Downloading SQLAlchemy-1.4.45-cp38-cp38-macosx_10_15_x86_64.whl (1.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 10.0 MB/s eta 0:00:00\n",
      "Collecting sqlparse<1,>=0.4.0\n",
      "  Using cached sqlparse-0.4.3-py3-none-any.whl (42 kB)\n",
      "Collecting pytz<2023\n",
      "  Using cached pytz-2022.7-py2.py3-none-any.whl (499 kB)\n",
      "Collecting querystring-parser<2\n",
      "  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting packaging<22\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: scipy<2 in /Users/josh/opt/anaconda3/envs/mlflow-62f9b69251cbd655a1308303dace7190a5738de8/lib/python3.8/site-packages (from mlflow->-r /Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/training/condaenv.x0w9p4s8.requirements.txt (line 1)) (1.9.3)\n",
      "Collecting Flask<3\n",
      "  Using cached Flask-2.2.2-py3-none-any.whl (101 kB)\n",
      "Collecting requests<3,>=2.17.3\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Collecting gitpython<4,>=2.1.0\n",
      "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 182.5/182.5 kB 4.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2 in /Users/josh/opt/anaconda3/envs/mlflow-62f9b69251cbd655a1308303dace7190a5738de8/lib/python3.8/site-packages (from mlflow->-r /Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/training/condaenv.x0w9p4s8.requirements.txt (line 1)) (1.23.4)\n",
      "Collecting databricks-cli<1,>=0.8.7\n",
      "  Using cached databricks-cli-0.17.4.tar.gz (82 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: scikit-learn<2 in /Users/josh/opt/anaconda3/envs/mlflow-62f9b69251cbd655a1308303dace7190a5738de8/lib/python3.8/site-packages (from mlflow->-r /Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/training/condaenv.x0w9p4s8.requirements.txt (line 1)) (1.1.3)\n",
      "Collecting markdown<4,>=3.3\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting alembic<2\n",
      "  Downloading alembic-1.9.0-py3-none-any.whl (210 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.2/210.2 kB 6.2 MB/s eta 0:00:00\n",
      "Collecting pyarrow<11,>=4.0.0\n",
      "  Downloading pyarrow-10.0.1-cp38-cp38-macosx_10_14_x86_64.whl (25.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 25.0/25.0 MB 23.8 MB/s eta 0:00:00\n",
      "Collecting protobuf<5,>=3.12.0\n",
      "  Downloading protobuf-4.21.12-cp37-abi3-macosx_10_9_universal2.whl (486 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 486.2/486.2 kB 10.3 MB/s eta 0:00:00\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.7/78.7 kB 2.3 MB/s eta 0:00:00\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-5.10.1-py3-none-any.whl (34 kB)\n",
      "Collecting pyjwt>=1.7.0\n",
      "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
      "Collecting oauthlib>=3.1.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting tabulate>=0.7.7\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/josh/opt/anaconda3/envs/mlflow-62f9b69251cbd655a1308303dace7190a5738de8/lib/python3.8/site-packages (from databricks-cli<1,>=0.8.7->mlflow->-r /Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/training/condaenv.x0w9p4s8.requirements.txt (line 1)) (1.16.0)\n",
      "Collecting urllib3>=1.26.0\n",
      "  Using cached urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Using cached websocket_client-1.4.2-py3-none-any.whl (55 kB)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting Werkzeug>=2.2.2\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools>=3.0 in /Users/josh/opt/anaconda3/envs/mlflow-62f9b69251cbd655a1308303dace7190a5738de8/lib/python3.8/site-packages (from gunicorn<21->mlflow->-r /Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/training/condaenv.x0w9p4s8.requirements.txt (line 1)) (65.5.0)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.11.0-py3-none-any.whl (6.6 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.1-cp38-cp38-macosx_10_9_x86_64.whl (13 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting pyparsing>=2.2.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "Collecting python-dateutil>=2.7\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.6-cp38-cp38-macosx_10_9_x86_64.whl (240 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 240.6/240.6 kB 6.3 MB/s eta 0:00:00\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.3.0-cp38-cp38-macosx_10_10_x86_64.whl (3.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 22.9 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp38-cp38-macosx_10_9_x86_64.whl (65 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/josh/opt/anaconda3/envs/mlflow-62f9b69251cbd655a1308303dace7190a5738de8/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow->-r /Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/training/condaenv.x0w9p4s8.requirements.txt (line 1)) (2022.9.24)\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/josh/opt/anaconda3/envs/mlflow-62f9b69251cbd655a1308303dace7190a5738de8/lib/python3.8/site-packages (from scikit-learn<2->mlflow->-r /Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/training/condaenv.x0w9p4s8.requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/josh/opt/anaconda3/envs/mlflow-62f9b69251cbd655a1308303dace7190a5738de8/lib/python3.8/site-packages (from scikit-learn<2->mlflow->-r /Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/training/condaenv.x0w9p4s8.requirements.txt (line 1)) (2.2.0)\n",
      "Collecting slicer==0.0.7\n",
      "  Using cached slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Collecting numba\n",
      "  Downloading numba-0.56.4-cp38-cp38-macosx_10_14_x86_64.whl (2.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 22.4 MB/s eta 0:00:00\n",
      "Collecting tqdm>4.25.0\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-2.0.1-cp38-cp38-macosx_10_15_x86_64.whl (203 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 203.6/203.6 kB 5.2 MB/s eta 0:00:00\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Using cached llvmlite-0.39.1-cp38-cp38-macosx_10_9_x86_64.whl (25.5 MB)\n",
      "Building wheels for collected packages: databricks-cli\n",
      "  Building wheel for databricks-cli (setup.py): started\n",
      "  Building wheel for databricks-cli (setup.py): finished with status 'done'\n",
      "  Created wheel for databricks-cli: filename=databricks_cli-0.17.4-py3-none-any.whl size=142875 sha256=d12ce71daa893406666c4eb739b8ff9ae0478161e9a55b01c7f927724c2871e2\n",
      "  Stored in directory: /Users/josh/Library/Caches/pip/wheels/0a/0b/75/44edb38430dc44de74324d6e72d91d0d14d21df90349767335\n",
      "Successfully built databricks-cli\n",
      "Installing collected packages: pytz, zipp, websocket-client, urllib3, tqdm, tabulate, sqlparse, smmap, slicer, querystring-parser, pyyaml, python-dateutil, pyparsing, pyjwt, pyarrow, protobuf, pillow, oauthlib, MarkupSafe, llvmlite, kiwisolver, itsdangerous, idna, gunicorn, greenlet, fonttools, entrypoints, cycler, contourpy, cloudpickle, click, charset-normalizer, Werkzeug, sqlalchemy, requests, pandas, packaging, Mako, Jinja2, importlib-resources, importlib-metadata, gitdb, numba, matplotlib, markdown, gitpython, Flask, docker, databricks-cli, alembic, shap, mlflow\n",
      "Successfully installed Flask-2.2.2 Jinja2-3.1.2 Mako-1.2.4 MarkupSafe-2.1.1 Werkzeug-2.2.2 alembic-1.9.0 charset-normalizer-2.1.1 click-8.1.3 cloudpickle-2.2.0 contourpy-1.0.6 cycler-0.11.0 databricks-cli-0.17.4 docker-6.0.1 entrypoints-0.4 fonttools-4.38.0 gitdb-4.0.10 gitpython-3.1.29 greenlet-2.0.1 gunicorn-20.1.0 idna-3.4 importlib-metadata-5.2.0 importlib-resources-5.10.1 itsdangerous-2.1.2 kiwisolver-1.4.4 llvmlite-0.39.1 markdown-3.4.1 matplotlib-3.6.2 mlflow-2.0.1 numba-0.56.4 oauthlib-3.2.2 packaging-21.3 pandas-1.5.2 pillow-9.3.0 protobuf-4.21.12 pyarrow-10.0.1 pyjwt-2.6.0 pyparsing-3.0.9 python-dateutil-2.8.2 pytz-2022.7 pyyaml-6.0 querystring-parser-1.2.4 requests-2.28.1 shap-0.41.0 slicer-0.0.7 smmap-5.0.0 sqlalchemy-1.4.45 sqlparse-0.4.3 tabulate-0.9.0 tqdm-4.64.1 urllib3-1.26.13 websocket-client-1.4.2 zipp-3.11.0\n",
      "\n",
      "done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate mlflow-62f9b69251cbd655a1308303dace7190a5738de8\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "Retrieving notices: ...working... done\n",
      "2022/12/19 16:51:31 INFO mlflow.projects.utils: === Created directory /var/folders/xv/n51qjph14_52lj9y4706w6sc0000gn/T/tmphlkux4jl for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2022/12/19 16:51:31 INFO mlflow.projects.backend.local: === Running command 'source /Users/josh/opt/anaconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-62f9b69251cbd655a1308303dace7190a5738de8 1>&2 && python train.py 0.1 0.1' in run with ID 'c5080bf26e24443faaee06a757507d16' === \n",
      "Elasticnet model (alpha=0.100000, l1_ratio=0.100000):\n",
      "  RMSE: 0.7792546522251949\n",
      "  MAE: 0.6112547988118586\n",
      "  R2: 0.2157063843066196\n",
      "2022/12/19 16:51:38 INFO mlflow.projects: === Run (ID 'c5080bf26e24443faaee06a757507d16') succeeded ===\n"
     ]
    }
   ],
   "source": [
    "!mlflow run ./training -P alpha=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/12/19 16:55:28 INFO mlflow.utils.conda: Conda environment mlflow-62f9b69251cbd655a1308303dace7190a5738de8 already exists.\n",
      "2022/12/19 16:55:28 INFO mlflow.projects.utils: === Created directory /var/folders/xv/n51qjph14_52lj9y4706w6sc0000gn/T/tmp9os3q7o8 for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2022/12/19 16:55:28 INFO mlflow.projects.backend.local: === Running command 'source /Users/josh/opt/anaconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-62f9b69251cbd655a1308303dace7190a5738de8 1>&2 && python train.py 1.0 0.1' in run with ID 'd2a6d8a5c3744af39227f5d632794d5a' === \n",
      "Elasticnet model (alpha=1.000000, l1_ratio=0.100000):\n",
      "  RMSE: 0.8107373707184711\n",
      "  MAE: 0.6241295925236752\n",
      "  R2: 0.15105362812007328\n",
      "2022/12/19 16:55:33 INFO mlflow.projects: === Run (ID 'd2a6d8a5c3744af39227f5d632794d5a') succeeded ===\n"
     ]
    }
   ],
   "source": [
    "!mlflow run ./training -P alpha=1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLflow Tracking\n",
    "\n",
    "The `train.py` script uses the `mlflow.log_param()` and `mlflow.log_metric()` commands to track each experiment. These are part of the `MLtrack` API, which tracks experiments parameters and results. These can be stored on a remote server, which can then be shared across the entire team. However, on our example we will store these locally on a `mlruns` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mc5080bf26e24443faaee06a757507d16\u001b[m\u001b[m meta.yaml\n",
      "\u001b[1m\u001b[36md2a6d8a5c3744af39227f5d632794d5a\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls mlruns/0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also run `mlflow ui` to show these visually. This will start the MLflow server in http://localhost:5000.\n",
    "\n",
    "```bash\n",
    "$ mlflow ui\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLFlow UI](./images/mlflow-ui.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLflow Model\n",
    "\n",
    "The `MLmodel` file allows us to version and share models easily. Below we can see an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mc5080bf26e24443faaee06a757507d16\u001b[m\u001b[m meta.yaml\n",
      "\u001b[1m\u001b[36md2a6d8a5c3744af39227f5d632794d5a\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls ./mlruns/0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = 'c5080bf26e24443faaee06a757507d16'\n",
    "model_b = 'd2a6d8a5c3744af39227f5d632794d5a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact_path: model\n",
      "flavors:\n",
      "  python_function:\n",
      "    env: conda.yaml\n",
      "    loader_module: mlflow.sklearn\n",
      "    model_path: model.pkl\n",
      "    python_version: 3.8.13\n",
      "  sklearn:\n",
      "    code: null\n",
      "    pickled_model: model.pkl\n",
      "    serialization_format: cloudpickle\n",
      "    sklearn_version: 1.1.2\n",
      "mlflow_version: 1.28.0\n",
      "model_uuid: 360cabd7b83146ee94bbc4fe8d1b2e9d\n",
      "run_id: c5080bf26e24443faaee06a757507d16\n",
      "utc_time_created: '2022-12-19 21:51:35.798350'\n"
     ]
    }
   ],
   "source": [
    "!cat ./mlruns/0/c5080bf26e24443faaee06a757507d16/artifacts/model/MLmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above the `MLmodel` keeps track, between others, of\n",
    "\n",
    "- The experiment id, `5a6be5a1ef844783a50a6577745dbdc3`\n",
    "- Date \n",
    "- Version of `sklearn` \n",
    "- How the model was stored\n",
    "\n",
    "As we shall see shortly, the pre-packaged Seldon's model server will use this file to serve this model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pack Model A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c5080bf26e24443faaee06a757507d16\n"
     ]
    }
   ],
   "source": [
    "!ls mlruns/0 | sed -n 1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting packages...\n",
      "Packing environment at '/Users/josh/opt/anaconda3/envs/mlflow-ab' to 'mlruns/0/c5080bf26e24443faaee06a757507d16/artifacts/model/environment.tar.gz'\n",
      "[########################################] | 100% Completed |  0.1s\n"
     ]
    }
   ],
   "source": [
    "!conda pack -o mlruns/0/$(ls mlruns/0 | sed -n 1p)/artifacts/model/environment.tar.gz -f"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pack Model B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d2a6d8a5c3744af39227f5d632794d5a\n"
     ]
    }
   ],
   "source": [
    "!ls mlruns/0 | sed -n 2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting packages...\n",
      "Packing environment at '/Users/josh/opt/anaconda3/envs/mlflow-ab' to 'mlruns/0/d2a6d8a5c3744af39227f5d632794d5a/artifacts/model/environment.tar.gz'\n",
      "[########################################] | 100% Completed |  0.1s\n"
     ]
    }
   ],
   "source": [
    "!conda pack -o mlruns/0/$(ls mlruns/0 | sed -n 2p)/artifacts/model/environment.tar.gz -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload models (optional)\n",
    "\n",
    "As a last step, we will persist the models we have just trained using `MLflow`. For that, we will upload them into Google Cloud Storage. Note that to run these commands you need write access into the `gs://seldon-models` bucket and you need to have `gsutil` set up.\n",
    "\n",
    "Note that in a production setting, MLflow would be configured to log models against a persistent data store (e.g. GCS, Minio, etc.). In that case, this manual step wouldn't be needed.\n",
    "\n",
    "We will upload both versions of the model to:\n",
    "\n",
    "- `gs://seldon-models/mlflow/model-a`\n",
    "- `gs://seldon-models/mlflow/model-b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minioClient = Minio(\"35.185.70.254:9000\", \"admin@seldon.io\", \"12341234\", secure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minioClient.list_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_local_directory_to_minio(local_path: str, bucket_name: str, folder_name: str):\n",
    "    assert os.path.isdir(local_path)\n",
    "\n",
    "    for local_file in glob.glob(local_path + '/**'):\n",
    "        local_file = local_file.replace(os.sep, \"/\")\n",
    "        if not os.path.isfile(local_file):\n",
    "            upload_local_directory_to_minio(\n",
    "                local_file, bucket_name)\n",
    "        else:\n",
    "            remote_path = os.path.join(\n",
    "                local_file[1 + len(local_path):])\n",
    "            remote_path = remote_path.replace(\n",
    "                os.sep, \"/\")\n",
    "            remote_path = folder_name + \"/\" + remote_path\n",
    "            minioClient.fput_object(bucket_name, remote_path, local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_local_directory_to_minio(f\"mlruns/0/{RUN}/artifacts/model\", f\"{BUCKET_NAME}\", \"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://mlruns/0/c5080bf26e24443faaee06a757507d16/artifacts/model/MLmodel [Content-Type=application/octet-stream]...\n",
      "Copying file://mlruns/0/c5080bf26e24443faaee06a757507d16/artifacts/model/conda.yaml [Content-Type=application/octet-stream]...\n",
      "Copying file://mlruns/0/c5080bf26e24443faaee06a757507d16/artifacts/model/environment.tar.gz [Content-Type=application/x-tar]...\n",
      "Copying file://mlruns/0/c5080bf26e24443faaee06a757507d16/artifacts/model/model.pkl [Content-Type=application/octet-stream]...\n",
      "\\ [4 files][  7.2 KiB/  7.2 KiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://mlruns/0/c5080bf26e24443faaee06a757507d16/artifacts/model/python_env.yaml [Content-Type=application/octet-stream]...\n",
      "Copying file://mlruns/0/c5080bf26e24443faaee06a757507d16/artifacts/model/requirements.txt [Content-Type=text/plain]...\n",
      "| [6 files][  7.4 KiB/  7.4 KiB]                                                \n",
      "Operation completed over 6 objects/7.4 KiB.                                      \n",
      "Copying file://mlruns/0/d2a6d8a5c3744af39227f5d632794d5a/artifacts/model/MLmodel [Content-Type=application/octet-stream]...\n",
      "Copying file://mlruns/0/d2a6d8a5c3744af39227f5d632794d5a/artifacts/model/conda.yaml [Content-Type=application/octet-stream]...\n",
      "Copying file://mlruns/0/d2a6d8a5c3744af39227f5d632794d5a/artifacts/model/environment.tar.gz [Content-Type=application/x-tar]...\n",
      "Copying file://mlruns/0/d2a6d8a5c3744af39227f5d632794d5a/artifacts/model/model.pkl [Content-Type=application/octet-stream]...\n",
      "\\ [4 files][  7.2 KiB/  7.2 KiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://mlruns/0/d2a6d8a5c3744af39227f5d632794d5a/artifacts/model/python_env.yaml [Content-Type=application/octet-stream]...\n",
      "Copying file://mlruns/0/d2a6d8a5c3744af39227f5d632794d5a/artifacts/model/requirements.txt [Content-Type=text/plain]...\n",
      "\\ [6 files][  7.4 KiB/  7.4 KiB]                                                \n",
      "Operation completed over 6 objects/7.4 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r mlruns/0/c5080bf26e24443faaee06a757507d16/artifacts/model/* gs://josh-seldon/ab-test/model-a\n",
    "!gsutil cp -r mlruns/0/d2a6d8a5c3744af39227f5d632794d5a/artifacts/model/* gs://josh-seldon/ab-test/model-b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Serving\n",
    "\n",
    "To serve this model we will use Seldon."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy models v1 Protocol\n",
    "\n",
    "Once the cluster is set up, the next step will to upload these models into a common repository and to deploy two `SeldonDeployment` specs to `k8s`. As we can see below, we will route 50% of the traffic to each of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./serving/model-a-b.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./serving/model-a-b.yaml\n",
    "---\n",
    "apiVersion: machinelearning.seldon.io/v1alpha2\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: wines-classifier\n",
    "spec:\n",
    "  annotations:\n",
    "    seldon.io/executor: \"false\" \n",
    "  predictors:\n",
    "  - graph:\n",
    "      children: []\n",
    "      implementation: MLFLOW_SERVER\n",
    "      modelUri: gs://josh-seldon/ab-test/model-a\n",
    "      name: wines-classifier\n",
    "    name: model-a\n",
    "    replicas: 1\n",
    "    traffic: 50\n",
    "    componentSpecs:\n",
    "    - spec:\n",
    "        # We are setting high failureThreshold as installing conda dependencies\n",
    "        # can take long time and we want to avoid k8s killing the container prematurely\n",
    "        containers:\n",
    "        - name: wines-classifier\n",
    "          livenessProbe:\n",
    "            initialDelaySeconds: 100\n",
    "            failureThreshold: 500\n",
    "            periodSeconds: 5\n",
    "            successThreshold: 1\n",
    "            httpGet:\n",
    "              path: /health/ping\n",
    "              port: http\n",
    "              scheme: HTTP\n",
    "          readinessProbe:\n",
    "            initialDelaySeconds: 100\n",
    "            failureThreshold: 500\n",
    "            periodSeconds: 5\n",
    "            successThreshold: 1\n",
    "            httpGet:\n",
    "              path: /health/ping\n",
    "              port: http\n",
    "              scheme: HTTP\n",
    "  - graph:\n",
    "      children: []\n",
    "      implementation: MLFLOW_SERVER\n",
    "      modelUri: gs://josh-seldon/ab-test/model-b\n",
    "      name: wines-classifier\n",
    "    name: model-b\n",
    "    replicas: 1\n",
    "    traffic: 50\n",
    "    componentSpecs:\n",
    "    - spec:\n",
    "        # We are setting high failureThreshold as installing conda dependencies\n",
    "        # can take long time and we want to avoid k8s killing the container prematurely\n",
    "        containers:\n",
    "        - name: wines-classifier\n",
    "          livenessProbe:\n",
    "            initialDelaySeconds: 100\n",
    "            failureThreshold: 500\n",
    "            periodSeconds: 5\n",
    "            successThreshold: 1\n",
    "            httpGet:\n",
    "              path: /health/ping\n",
    "              port: http\n",
    "              scheme: HTTP\n",
    "          readinessProbe:\n",
    "            initialDelaySeconds: 100\n",
    "            failureThreshold: 500\n",
    "            periodSeconds: 5\n",
    "            successThreshold: 1\n",
    "            httpGet:\n",
    "              path: /health/ping\n",
    "              port: http\n",
    "              scheme: HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/wines-classifier configured\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f ./serving/model-a-b.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io \"wines-classifier\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f ./serving/model-a-b.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify these have been deployed by checking the pods and `SeldonDeployment` resources in the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test models\n",
    "\n",
    "We will now run a sample query to test that the inference graph is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'names': [], 'ndarray': [5.550530190667395]},\n",
       " 'meta': {'requestPath': {'wines-classifier': 'seldonio/mlflowserver:1.15.0'}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "inference_request = {\n",
    "    \"data\": {\n",
    "        \"names\": [\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\"],\n",
    "        \"ndarray\": [\n",
    "            [7, 0.27, 0.36, 20.7, 0.045, 45, 170, 1.001, 3, 0.45, 8.8]\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "endpoint = \"http://localhost:8080/seldon/default/wines-classifier/api/v1.0/predictions\"\n",
    "response = requests.post(endpoint, json=inference_request)\n",
    "\n",
    "response.json()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy models v1 Protocol\n",
    "\n",
    "Once the cluster is set up, the next step will to upload these models into a common repository and to deploy two `SeldonDeployment` specs to `k8s`. As we can see below, we will route 50% of the traffic to each of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./serving/model-a-b.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./serving/model-a-b.yaml\n",
    "---\n",
    "apiVersion: machinelearning.seldon.io/v1alpha2\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: wines-classifier\n",
    "spec:\n",
    "  annotations:\n",
    "    seldon.io/executor: \"false\" \n",
    "  predictors:\n",
    "  - graph:\n",
    "      children: []\n",
    "      implementation: MLFLOW_SERVER\n",
    "      modelUri: gs://josh-seldon/ab-test/model-a\n",
    "      name: wines-classifier\n",
    "    name: model-a\n",
    "    replicas: 1\n",
    "    traffic: 50\n",
    "    componentSpecs:\n",
    "    - spec:\n",
    "        # We are setting high failureThreshold as installing conda dependencies\n",
    "        # can take long time and we want to avoid k8s killing the container prematurely\n",
    "        containers:\n",
    "        - name: wines-classifier\n",
    "          livenessProbe:\n",
    "            initialDelaySeconds: 100\n",
    "            failureThreshold: 500\n",
    "            periodSeconds: 5\n",
    "            successThreshold: 1\n",
    "            httpGet:\n",
    "              path: /health/ping\n",
    "              port: http\n",
    "              scheme: HTTP\n",
    "          readinessProbe:\n",
    "            initialDelaySeconds: 100\n",
    "            failureThreshold: 500\n",
    "            periodSeconds: 5\n",
    "            successThreshold: 1\n",
    "            httpGet:\n",
    "              path: /health/ping\n",
    "              port: http\n",
    "              scheme: HTTP\n",
    "  - graph:\n",
    "      children: []\n",
    "      implementation: MLFLOW_SERVER\n",
    "      modelUri: gs://josh-seldon/ab-test/model-b\n",
    "      name: wines-classifier\n",
    "    name: model-b\n",
    "    replicas: 1\n",
    "    traffic: 50\n",
    "    componentSpecs:\n",
    "    - spec:\n",
    "        # We are setting high failureThreshold as installing conda dependencies\n",
    "        # can take long time and we want to avoid k8s killing the container prematurely\n",
    "        containers:\n",
    "        - name: wines-classifier\n",
    "          livenessProbe:\n",
    "            initialDelaySeconds: 100\n",
    "            failureThreshold: 500\n",
    "            periodSeconds: 5\n",
    "            successThreshold: 1\n",
    "            httpGet:\n",
    "              path: /health/ping\n",
    "              port: http\n",
    "              scheme: HTTP\n",
    "          readinessProbe:\n",
    "            initialDelaySeconds: 100\n",
    "            failureThreshold: 500\n",
    "            periodSeconds: 5\n",
    "            successThreshold: 1\n",
    "            httpGet:\n",
    "              path: /health/ping\n",
    "              port: http\n",
    "              scheme: HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/wines-classifier configured\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f ./serving/model-a-b.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io \"wines-classifier\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f ./serving/model-a-b.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test models\n",
    "\n",
    "We will now run a sample query to test that the inference graph is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'names': [], 'ndarray': [5.601358618516229]},\n",
       " 'meta': {'requestPath': {'wines-classifier': 'seldonio/mlflowserver:1.15.0'}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "inference_request = {\n",
    "    \"data\": {\n",
    "        \"names\": [\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\"],\n",
    "        \"ndarray\": [\n",
    "            [7, 0.27, 0.36, 20.7, 0.045, 45, 170, 1.001, 3, 0.45, 8.8]\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "endpoint = \"http://localhost:8080/seldon/default/wines-classifier/api/v1.0/predictions\"\n",
    "response = requests.post(endpoint, json=inference_request)\n",
    "\n",
    "response.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytics\n",
    "\n",
    "To access Grafana, it will be necessary to forward the port to the respective pod as we did previously to access the Seldon Core deployment.\n",
    "The credentials will be simply `admin` // `password`.\n",
    "\n",
    "This command needs to run constantly on the background, so **please make sure you run it on a separate terminal**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ kubectl port-forward \\\n",
    "    $(kubectl get pods \\\n",
    "        -l app=grafana-prom-server -o jsonpath='{.items[0].metadata.name}') \\\n",
    "    3000:3000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have both models running in production, we can analyse their performance using Seldon Core's integration with Prometheus and Grafana.\n",
    "To do so, we will iterate over the training set (which can be foud in `./training/wine-quality.csv`), making a request and sending the feedback of the prediction.\n",
    "\n",
    "Since the `/feedback` endpoint requires a `reward` signal (i.e. higher better), we will simulate one as\n",
    "\n",
    "$$\n",
    "  R(x_{n})\n",
    "    = \\begin{cases}\n",
    "        \\frac{1}{(y_{n} - f(x_{n}))^{2}} &, y_{n} \\neq f(x_{n}) \\\\\n",
    "        500 &, y_{n} = f(x_{n})\n",
    "      \\end{cases}\n",
    "$$\n",
    "\n",
    ", where $R(x_{n})$ is the reward for input point $x_{n}$, $f(x_{n})$ is our trained model and $y_{n}$ is the actual value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "array([[4.94992876]]) has type numpy.ndarray, but expected one of: int, float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/README.ipynb Cell 48\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/README.ipynb#X61sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     sc\u001b[39m.\u001b[39mfeedback(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/README.ipynb#X61sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         prediction_request\u001b[39m=\u001b[39mr\u001b[39m.\u001b[39mrequest,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/README.ipynb#X61sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         prediction_response\u001b[39m=\u001b[39mr\u001b[39m.\u001b[39mresponse,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/README.ipynb#X61sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m         reward\u001b[39m=\u001b[39mreward)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/README.ipynb#X61sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m reward[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/README.ipynb#X61sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m df\u001b[39m.\u001b[39;49mapply(_test_row, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/pandas/core/frame.py:8848\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8837\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   8839\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   8840\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   8841\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8846\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   8847\u001b[0m )\n\u001b[0;32m-> 8848\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/pandas/core/apply.py:733\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    731\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 733\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/pandas/core/apply.py:857\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 857\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    859\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/pandas/core/apply.py:873\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    871\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    872\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    874\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    875\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    876\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    877\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32m/Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/README.ipynb Cell 48\u001b[0m in \u001b[0;36m_test_row\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/README.ipynb#X61sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m y_pred \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mresponse[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtensor\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mvalues\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/README.ipynb#X61sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m reward \u001b[39m=\u001b[39m _get_reward(y, y_pred)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/README.ipynb#X61sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m sc\u001b[39m.\u001b[39;49mfeedback(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/README.ipynb#X61sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     prediction_request\u001b[39m=\u001b[39;49mr\u001b[39m.\u001b[39;49mrequest,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/README.ipynb#X61sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     prediction_response\u001b[39m=\u001b[39;49mr\u001b[39m.\u001b[39;49mresponse,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/README.ipynb#X61sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     reward\u001b[39m=\u001b[39;49mreward)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/Documents/job-2021/seldon/mlflow-ab-test/deliverable/README.ipynb#X61sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mreturn\u001b[39;00m reward[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/seldon_core/seldon_client.py:459\u001b[0m, in \u001b[0;36mSeldonClient.feedback\u001b[0;34m(self, prediction_request, prediction_response, prediction_truth, reward, gateway, transport, deployment_name, payload_type, gateway_endpoint, microservice_endpoint, method, shape, namespace, gateway_prefix, client_return_type, raw_request, ssl)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m k[\u001b[39m\"\u001b[39m\u001b[39mgateway\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mambassador\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m k[\u001b[39m\"\u001b[39m\u001b[39mgateway\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mistio\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    458\u001b[0m     \u001b[39mif\u001b[39;00m k[\u001b[39m\"\u001b[39m\u001b[39mtransport\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrest\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 459\u001b[0m         \u001b[39mreturn\u001b[39;00m rest_feedback_gateway(\n\u001b[1;32m    460\u001b[0m             prediction_request,\n\u001b[1;32m    461\u001b[0m             prediction_response,\n\u001b[1;32m    462\u001b[0m             prediction_truth,\n\u001b[1;32m    463\u001b[0m             reward,\n\u001b[1;32m    464\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mk,\n\u001b[1;32m    465\u001b[0m         )\n\u001b[1;32m    466\u001b[0m     \u001b[39melif\u001b[39;00m k[\u001b[39m\"\u001b[39m\u001b[39mtransport\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgrpc\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    467\u001b[0m         \u001b[39mreturn\u001b[39;00m grpc_feedback_gateway(\n\u001b[1;32m    468\u001b[0m             prediction_request,\n\u001b[1;32m    469\u001b[0m             prediction_response,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mk,\n\u001b[1;32m    473\u001b[0m         )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/seldon_core/seldon_client.py:2122\u001b[0m, in \u001b[0;36mrest_feedback_gateway\u001b[0;34m(prediction_request, prediction_response, prediction_truth, reward, deployment_name, namespace, gateway_endpoint, headers, gateway_prefix, client_return_type, raw_request, **kwargs)\u001b[0m\n\u001b[1;32m   2120\u001b[0m     payload \u001b[39m=\u001b[39m raw_request\n\u001b[1;32m   2121\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2122\u001b[0m     request \u001b[39m=\u001b[39m prediction_pb2\u001b[39m.\u001b[39;49mFeedback(\n\u001b[1;32m   2123\u001b[0m         request\u001b[39m=\u001b[39;49mprediction_request,\n\u001b[1;32m   2124\u001b[0m         response\u001b[39m=\u001b[39;49mprediction_response,\n\u001b[1;32m   2125\u001b[0m         reward\u001b[39m=\u001b[39;49mreward,\n\u001b[1;32m   2126\u001b[0m         truth\u001b[39m=\u001b[39;49mprediction_truth,\n\u001b[1;32m   2127\u001b[0m     )\n\u001b[1;32m   2128\u001b[0m     payload \u001b[39m=\u001b[39m feedback_to_json(request)\n\u001b[1;32m   2129\u001b[0m \u001b[39mif\u001b[39;00m gateway_prefix \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: array([[4.94992876]]) has type numpy.ndarray, but expected one of: int, float"
     ]
    }
   ],
   "source": [
    "### %%writefile feedback.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from seldon_core.seldon_client import SeldonClient\n",
    "\n",
    "sc = SeldonClient(\n",
    "    gateway=\"istio\", \n",
    "    namespace=\"default\",\n",
    "    gateway_endpoint=\"localhost:8080\",\n",
    "    deployment_name='wines-classifier')\n",
    "\n",
    "df = pd.read_csv(\"./training/wine-quality.csv\")\n",
    "\n",
    "def _get_reward(y, y_pred):\n",
    "    if y == y_pred:\n",
    "        return 500    \n",
    "    \n",
    "    return 1 / np.square(y - y_pred)\n",
    "\n",
    "def _test_row(row):\n",
    "    input_features = row[:-1]\n",
    "    feature_names = input_features.index.to_list()\n",
    "    X = input_features.values.reshape(1, -1)\n",
    "    y = row[-1].reshape(1, -1)\n",
    "    \n",
    "    r = sc.predict(\n",
    "        data=X,\n",
    "        names=feature_names)\n",
    "    \n",
    "    y_pred = r.response['data']['tensor']['values']\n",
    "    reward = _get_reward(y, y_pred)\n",
    "    sc.feedback(\n",
    "        prediction_request=r.request,\n",
    "        prediction_response=r.response,\n",
    "        reward=reward)\n",
    "    \n",
    "    return reward[0]\n",
    "\n",
    "df.apply(_test_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/urllib3/connection.py\", line 174, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/urllib3/util/connection.py\", line 95, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 398, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/urllib3/connection.py\", line 239, in request\n",
      "    super(HTTPConnection, self).request(method, url, body=body, headers=headers)\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/http/client.py\", line 1256, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/http/client.py\", line 1302, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/http/client.py\", line 1251, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/http/client.py\", line 1011, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/http/client.py\", line 951, in send\n",
      "    self.connect()\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/urllib3/connection.py\", line 205, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/urllib3/connection.py\", line 186, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fdc68d02910>: Failed to establish a new connection: [Errno 61] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/requests/adapters.py\", line 489, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/urllib3/util/retry.py\", line 592, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8083): Max retries exceeded with url: /seldon/default/wines-classifier/api/v1.0/predictions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc68d02910>: Failed to establish a new connection: [Errno 61] Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"feedback.py\", line 39, in <module>\n",
      "    df.apply(_test_row, axis=1)\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/pandas/core/frame.py\", line 8848, in apply\n",
      "    return op.apply().__finalize__(self, method=\"apply\")\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/pandas/core/apply.py\", line 733, in apply\n",
      "    return self.apply_standard()\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/pandas/core/apply.py\", line 857, in apply_standard\n",
      "    results, res_index = self.apply_series_generator()\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/pandas/core/apply.py\", line 873, in apply_series_generator\n",
      "    results[i] = self.f(v)\n",
      "  File \"feedback.py\", line 25, in _test_row\n",
      "    r = sc.predict(\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/seldon_core/seldon_client.py\", line 367, in predict\n",
      "    return rest_predict_gateway(**k)\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/seldon_core/seldon_client.py\", line 1546, in rest_predict_gateway\n",
      "    response_raw = requests.post(\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/requests/api.py\", line 115, in post\n",
      "    return request(\"post\", url, data=data, json=json, **kwargs)\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/requests/api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/requests/sessions.py\", line 587, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/requests/sessions.py\", line 701, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/josh/opt/anaconda3/envs/tmp-wine/lib/python3.8/site-packages/requests/adapters.py\", line 565, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8083): Max retries exceeded with url: /seldon/default/wines-classifier/api/v1.0/predictions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc68d02910>: Failed to establish a new connection: [Errno 61] Connection refused'))\n"
     ]
    }
   ],
   "source": [
    "!python feedback.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can now access the Grafana dashboard in http://localhost:3000 (credentials are `admin` // `password`). Inside the portal, we will go to the Prediction Analytics dashboard.\n",
    " \n",
    " \n",
    "We can see a snapshot below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Seldon Analytics](./images/seldon-analytics.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmp-wine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "6c61a94ef80df30edeab33a50faece201aaada47868665c37f02a84b5d984383"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
